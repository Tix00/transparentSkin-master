{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tix00-b/remote1/blob/main/Copia_di_test_colab_deeplabv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFhh6nXMUmL1"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u45-U4sfvkgR"
      },
      "outputs": [],
      "source": [
        "!pip install shutil\n",
        "!pip install os\n",
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "    \n",
        "source_dir = '/content/drive/MyDrive/models/SegmentationClassRaw_All'\n",
        "target_dir = '/content/drive/MyDrive/models/SegmentationClass_all'\n",
        "    \n",
        "file_names_old = os.listdir(source_dir)\n",
        "\n",
        "file_names_new = os.listdir(target_dir)\n",
        "i = 0\n",
        "totImg = 5000 + 28280\n",
        "k =0\n",
        "print(file_names_old)\n",
        "\n",
        "file_object = open('/content/drive/MyDrive/models/rimasugli.txt', 'w')\n",
        "# Append 'hello' at the end of file\n",
        "\n",
        "# Close the file\n",
        "\n",
        "with open('/content/drive/MyDrive/models/ImageSets/Segmentation_all/train.txt') as topo_file:\n",
        "    for line in topo_file:\n",
        "      #print(line[:-1]+\".png\")\n",
        "      if not ((line[:-1]+\".png\") in file_names_old):\n",
        "        print(line, k)\n",
        "        file_object.write(line + \"\\n\")\n",
        "        k = k + 1\n",
        "file_object.close()\n",
        "print(\"tot img\", totImg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omIs6fP5sUbc"
      },
      "source": [
        "ssad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gkS1B_V_pjv"
      },
      "outputs": [],
      "source": [
        "!pip install shutil\n",
        "!pip install os\n",
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "    \n",
        "source_dir = '/content/drive/MyDrive/models/SegmentationClassRaw_All'\n",
        "target_dir = '/content/drive/MyDrive/models/SegmentationClass_all'\n",
        "    \n",
        "file_names_old = os.listdir(source_dir)\n",
        "print(len(file_names_old))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AW3g17MWuc3",
        "outputId": "51a9b246-f16f-4e1e-da82-5c96b823a85a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: models/research: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cd models/research\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yL-Tmc2kVfuS"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N44n1BZYFyC"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVtKxtoDYLtY"
      },
      "outputs": [],
      "source": [
        "#From tensorflow/models/research/export \n",
        "!PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIekOCE16ySS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/models/research')\n",
        "import slim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0DutfaBY3a2"
      },
      "source": [
        "Local Dir: \"D:\\immagini progetto EI\\images\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZL0XFCFXTLZ",
        "outputId": "74cfae64-1769-4608-ab5c-ea2039669053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "#!cd drive\n",
        "!cd drive/MyDrive/models/research/deeplab/datasets/\n",
        "!dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KfVXv6qZMpL"
      },
      "outputs": [],
      "source": [
        "#!mkdir \"drive/MyDrive/models/SegmentationClassRaw\"\n",
        "\n",
        "!python drive/MyDrive/models/research/deeplab/datasets/remove_gt_colormap.py \\\n",
        " --original_gt_folder= \"drive/MyDrive/models/SegmentationClass_all\"\\\n",
        " --output_dir=\"drive/MyDrive/models/SegmentationClassRaw_All\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7evwycJfiry"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "\n",
        "!python drive/MyDrive/models/research/deeplab/datasets/remove_gt_colormap.py \\\n",
        " --original_gt_folder= \"/content/drive/MyDrive/models/SegmentationClass_fixed\"\\\n",
        " --output_dir=\"/content/drive/MyDrive/models/SegmentationClassRaw_fixed\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq8lp1xpMHDz"
      },
      "source": [
        "ATTENZIONE!!!!\n",
        "in remove_gt_colormap ho dovuto modificare all'interno del codice un valore. alla riga 77 ho assegnato manualmente la cartella delle GT manualmente. cambiarne il nome dalla casella sottostante Ã¨ inutile, farlo direttamente dal codice di remove_gt_colormap.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVsBofmELWyJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "\n",
        "!python drive/MyDrive/models/research/deeplab/datasets/remove_gt_colormap.py \\\n",
        " --original_gt_folder= \"/content/drive/MyDrive/models/SegmentationClass\"\\\n",
        " --output_dir=\"/content/drive/MyDrive/models/SegmentationClassRaw\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQBkvvGGrchn"
      },
      "source": [
        " powershell -command \"& {get-content input.txt|select-object -first 10}\" >output.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVNNdWSm_HDi",
        "outputId": "4816d0e0-4395-43e2-d783-795df81486c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['community', 'AUTHORS', 'orbit', 'ISSUES.md', 'README.md', '.github', 'official', '.gitignore', 'CONTRIBUTING.md', 'CODEOWNERS', 'LICENSE', 'tensorflow_models', '.git', 'research', '.ipynb_checkpoints', 'SegmentationClass', 'SegmentationClassRaw', 'ImageSets', 'JPEGImages', 'tfrecord']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(r'/content/drive/My Drive/models'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0dEvo0g_5Ra",
        "outputId": "c4ce77e5-e690-4e08-b8b5-d51e4dfd9024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgsWE0oTT7fk"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgc56NAtQnaD",
        "outputId": "7ebb5c7c-e205-41b0-aa56-120272afec12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models\n"
          ]
        }
      ],
      "source": [
        "cd drive/My Drive/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BC7HKDdrsHY5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/models')\n",
        "\n",
        "!python drive/MyDrive/models/research/deeplab/datasets/build_voc2012_data.py \\\n",
        "  --image_folder=\"/content/drive/MyDrive/models/JPEGImages_all\" \\\n",
        "  --semantic_segmentation_folder=\"/content/drive/MyDrive/models/SegmentationClassRaw_fixed\" \\\n",
        "  --list_folder=\"/content/drive/MyDrive/models/ImageSets/Segmentation_all\" \\\n",
        "  --image_format=\"jpg\" \\\n",
        "  --output_dir=\"/content/drive/MyDrive/models/tfrecord_all\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tBSoxi9QTOz",
        "outputId": "d5c66159-997c-4921-8b9f-ac4d2268812c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!cd drive\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l_FWQD6v8LZ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/models/research')\n",
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "\n",
        "!python /content/drive/MyDrive/models/research/deeplab/train.py --logtostderr \\\n",
        "--training_number_of_steps=10000 \\\n",
        "   --train_split=\"train\" \\\n",
        "   --model_variant=\"mobilenet_v2\" \\\n",
        "   --output_stride=16 \\\n",
        "   --decoder_output_stride=4 \\\n",
        "   --train_crop_size=\"513,513\" \\\n",
        "   --train_batch_size=5 \\\n",
        "   --dataset=\"pascal_voc_seg\" \\\n",
        "   --tf_initial_checkpoint=\"/content/drive/MyDrive/models/deeplabv3_mnv2_pascal_trainval/model.ckpt-30000\" \\\n",
        "   --train_logdir=\"/content/drive/MyDrive/models/checkpoint_mobile_all2\" \\\n",
        "   --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\n",
        "   --fine_tune_batch_norm=false \\\n",
        "   --initialize_last_layer=true \\\n",
        "   --last_layers_contain_logits_only=false"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "dir(tf)"
      ],
      "metadata": {
        "id": "RPaLsNixiQD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1HmqF3sVBsS"
      },
      "outputs": [],
      "source": [
        "!python /content/drive/MyDrive/models/research/deeplab/vis.py --logtostderr \\\n",
        "  --vis_split=\"val\" \\\n",
        "  --model_variant=\"xception_65\" \\\n",
        "  --output_stride=16 \\\n",
        "  --decoder_output_stride=4 \\\n",
        "  --vis_crop_size=\"513,513\" \\\n",
        "  --dataset=\"pascal_voc_seg\" \\\n",
        "  --checkpoint_dir=\"/content/drive/MyDrive/models/checkpoint_old\" \\\n",
        "  --vis_logdir=\"/content/drive/MyDrive/models/result_images\" \\\n",
        "  --dataset_dir=\"/content/drive/MyDrive/models/tfrecord\" \\\n",
        "  --max_number_of_iterations=1 \\\n",
        "  --min_size =513 \\\n",
        "  --max_size =513 \\\n",
        "  --eval_interval_secs=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIpXaDKNvu4g"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!python /content/drive/MyDrive/models/research/deeplab/vis.py --logtostderr \\\n",
        "  --vis_split=\"val\" \\\n",
        "  --model_variant=\"xception_65\" \\\n",
        "  --output_stride=16 \\\n",
        "    --atrous_rates=6 \\\n",
        "   --atrous_rates=12 \\\n",
        "   --atrous_rates=18 \\\n",
        "   --output_stride=16 \\\n",
        "  --decoder_output_stride= 4 \\\n",
        "  --vis_crop_size=\"513,513\" \\\n",
        "  --min_resize_value=513 \\\n",
        "  --max_resize_value=513 \\\n",
        "  --dataset=\"pascal_voc_seg\" \\\n",
        "  --checkpoint_dir=\"/content/drive/MyDrive/models/checkpoint_exc_all2\" \\\n",
        "  --vis_logdir=\"/content/drive/MyDrive/models/Result_img_exc_final\" \\\n",
        "  --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\n",
        "  --train_crop_size=513 \\\n",
        "  --max_number_of_iterations=1 \\\n",
        "  --eval_interval_secs=0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "-MbsetSreer0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "NqtTJmfdeer0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input(\"foba\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilq00sqsZQTs",
        "outputId": "09d99624-e591-4865-e557-bfe2b4c6500d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fobad\n",
            "d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du7dLB1xyx1v"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!python /content/drive/MyDrive/models/research/deeplab/train.py --logtostderr \\\n",
        "   --training_number_of_steps=30000 \\\n",
        "   --train_split=\"train\" \\\n",
        "   --model_variant=\"xception_65\" \\\n",
        "   --atrous_rates=6 \\\n",
        "   --atrous_rates=12 \\\n",
        "   --atrous_rates=18 \\\n",
        "   --output_stride=16 \\\n",
        "   --decoder_output_stride=4 \\\n",
        "  --train_crop_size=\"513,513\" \\\n",
        "   --train_batch_size=1 \\\n",
        "   --dataset=\"pascal_voc_seg\" \\\n",
        "   --tf_initial_checkpoint=\"/content/drive/MyDrive/models/deeplabv3_pascal_train_aug/model.ckpt\" \\\n",
        "   --train_logdir=\"/content/drive/MyDrive/models/checkpoint_exc_all2\" \\\n",
        "   --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\n",
        "   --fine_tune_batch_norm=false \\\n",
        "   --initialize_last_layer=true \\\n",
        "   --last_layers_contain_logits_only=false"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz0Pwns-59SJ"
      },
      "source": [
        "Esporto i checkpoint in un file utilizzabile\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_util\n",
        "saver = tf.train.import_meta_graph('/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000.meta', clear_devices=True)\n",
        "graph = tf.get_default_graph()\n",
        "input_graph_def = graph.as_graph_def()\n",
        "sess = tf.Session()\n",
        "saver.restore(sess, \"/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000\")\n",
        "\n",
        "\n",
        "dir(graph)\n"
      ],
      "metadata": {
        "id": "iPm39YigvONe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esporta modello"
      ],
      "metadata": {
        "id": "43H33DhB5JGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!python /content/drive/MyDrive/models/research/deeplab/export_model.py --logtostderr \\\n",
        "--model_variant=\"xception_65\"\\\n",
        "--atrous_rates=6 \\\n",
        "--atrous_rates=12 \\\n",
        "--atrous_rates=18 \\\n",
        "--output_stride=16 \\\n",
        "--crop_size=513 \\\n",
        "--crop_size=513\\\n",
        "--decoder_output_stride=4\\\n",
        "--num_classes=21\\\n",
        "--export_path=\"/content/drive/MyDrive/models/frozen_graph/prova21.pb\"\\\n",
        "--checkpoint_path=\"/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000\" \\"
      ],
      "metadata": {
        "id": "HwEcqo4d5GFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "!python /content/drive/MyDrive/models/research/deeplab/export_model.py \\\n",
        "--logtostderr \\\n",
        "--export_path=\"/content/drive/MyDrive/models/frozen_graph/newmodeltrainval.pb\" \\\n",
        "--checkpoint_path=\"/content/drive/MyDrive/models/ck_new/model.ckpt-30000\" \\\n",
        "--vis_split=\"trainval\" \\\n",
        "--model_variant=\"xception_65\" \\\n",
        "--save_inference_graph=True \\\n",
        "--atrous_rates=6 \\\n",
        "--atrous_rates=12 \\\n",
        "--atrous_rates=18 \\\n",
        "--output_stride=16 \\\n",
        "--decoder_output_stride=4 \\\n",
        "--vis_crop_size=513 \\\n",
        "--vis_crop_size=513 \\\n",
        "--dataset=\"pascal_voc_seg\" \\"
      ],
      "metadata": {
        "id": "FEb4faLbUUaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepLabelModel:\n",
        "  def __init__(self, accuracy_over_speed = True):\n",
        "    self.EXE_DIR = os.getcwd()  # example-XXXNet.exe ì¤íëë ê²½ë¡\n",
        "    self.BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "    self.SLIM_DIR = os.path.join(self.BASE_DIR, 'slim')\n",
        "\n",
        "    sys.path.append(self.BASE_DIR)\n",
        "    sys.path.append(self.SLIM_DIR)\n",
        "    import ade20k_label_color # need BASE_DIR append\n",
        "\n",
        "    self.DEEP_LAB_DIR = os.path.join(self.BASE_DIR, 'deeplab')\n",
        "    self.WEIGHTS_DIR = os.path.join(self.DEEP_LAB_DIR, 'weights')\n",
        "\n",
        "    if accuracy_over_speed is True:\n",
        "      self.MODEL_NAME = 'deeplabv3_xception_ade20k_train'\n",
        "      self.INPUT_SIZE = (513, 513)  # (Height, Width) tuple\n",
        "    else:\n",
        "      self.MODEL_NAME = 'deeplabv3_mnv2_ade20k_train_2018_12_03'\n",
        "      self.INPUT_SIZE = (257, 257) # (Height, Width) tuple\n",
        "\n",
        "    self.PATH_TO_CKPT = self.MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "    self.PATH_TO_CKPT = os.path.join(self.WEIGHTS_DIR, self.PATH_TO_CKPT)\n",
        "\n",
        "    self.CLASS_LABEL = ade20k_label_color.ade20k_label\n",
        "    self.CLASS_COLOR = ade20k_label_color.ade20k_color\n",
        "\n",
        "    # Start TF\n",
        "    self.config = tf.ConfigProto()\n",
        "    self.config.allow_soft_placement = True\n",
        "    self.config.log_device_placement = False\n",
        "    self.config.gpu_options.allow_growth = True\n",
        "    self.sess = tf.Session(config=self.config)\n",
        "\n",
        "    with tf.gfile.GFile(self.PATH_TO_CKPT, 'rb') as fid:\n",
        "      graph_def = tf.GraphDef()\n",
        "      graph_def.ParseFromString(fid.read())\n",
        "      self.sess.graph.as_default()\n",
        "      tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "    # specification of DeepLabel defined by google\n",
        "    self.INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "    self.OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "\n",
        "    self.input_tensor = self.sess.graph.get_tensor_by_name(self.INPUT_TENSOR_NAME)\n",
        "    self.output_tensor = self.sess.graph.get_tensor_by_name(self.OUTPUT_TENSOR_NAME)\n",
        "\n",
        "  def inferDeepLabel(self, input_image):\n",
        "    src_height, src_width = input_image.shape[:2] # original size\n",
        "    input_image = cv2.resize(input_image, self.INPUT_SIZE) # input tensor size\n",
        "    input_image = np.expand_dims(input_image, axis=0) # input tensor dim\n",
        "\n",
        "    #start = time.time()\n",
        "    result = self.sess.run(\n",
        "      self.output_tensor, feed_dict={self.INPUT_TENSOR_NAME: input_image}\n",
        "    )\n",
        "    result = np.squeeze(result, axis=0)\n",
        "    #end = time.time()\n",
        "    #print('inferDeepLabel FPS: ', 1 / (end - start))\n",
        "\n",
        "    result = cv2.resize(result, (src_width, src_height), interpolation=cv2.INTER_NEAREST) # original size\n",
        "\n",
        "    return result\n",
        "\n",
        "  def decorate(self, result):\n",
        "    src_height, src_width = result.shape[:2] # original size\n",
        "    visu = np.zeros((src_height, src_width, 3), np.uint8)\n",
        "\n",
        "    # loop over the image, pixel by pixel\n",
        "    for y in range(0, src_height):\n",
        "      for x in range(0, src_width):\n",
        "        # threshold the pixel\n",
        "        visu[y, x] = self.CLASS_COLOR[result[y, x]]\n",
        "\n",
        "    # return the decorated image\n",
        "    return visu"
      ],
      "metadata": {
        "id": "sw-bHMGzMmeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import tensorflow as tf\n",
        "frozen_graph=\"/content/drive/MyDrive/models/frozen_graph/prova.pb\"\n",
        "with tf.gfile.GFile(frozen_graph, \"rb\") as f:\n",
        "    restored_graph_def = tf.GraphDef()\n",
        "    restored_graph_def.ParseFromString(f.read())\n",
        "\n",
        "with tf.Graph().as_default() as graph:\n",
        "    tf.import_graph_def(\n",
        "        restored_graph_def,\n",
        "        input_map=None,\n",
        "        return_elements=None,\n",
        "        name=\"\"\n",
        "        )\n",
        "    \n",
        "for n in tf.get_default_graph().as_graph_def().node:\n",
        "  print(n.name)"
      ],
      "metadata": {
        "id": "1i3bfuRe8rDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt0CkOmSBou3",
        "outputId": "9958c6dc-9703-4db6-ef84-e4e942d92d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import tensorflow as tf # Default graph is initialized when the library is imported\n",
        "import os\n",
        "from tensorflow.python.platform import gfile\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import misc\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "  \n",
        "with tf.Graph().as_default() as graph: # Set default graph as graph\n",
        "\n",
        "           with tf.Session() as sess:\n",
        "                # Load the graph in graph_def\n",
        "                print(\"load graph\")\n",
        "\n",
        "                # We load the protobuf file from the disk and parse it to retrive the unserialized graph_drf\n",
        "                with gfile.FastGFile(\"/content/drive/MyDrive/models/frozen_graph/prova.pb\",'rb') as f:\n",
        "\n",
        "                                print(\"Load Image...\")\n",
        "                                # Read the image & get statstics\n",
        "                                image = cv2.imread('/content/drive/MyDrive/models/0000631.jpg')\n",
        "                                image = image.astype(float)\n",
        "                                #image = tf.squeeze(image)\n",
        "                                image = np.expand_dims(image, axis=0)\n",
        "                                Input_image_shape=image.shape\n",
        "                                #height,width,channels = Input_image_shape\n",
        "\n",
        "                                print(\"Plot image...\")\n",
        "                                #scipy.misc.imshow(image)\n",
        "\n",
        "                                # Set FCN graph to the default graph\n",
        "                                graph_def = tf.GraphDef()\n",
        "                                graph_def.ParseFromString(f.read())\n",
        "                                sess.graph.as_default()\n",
        "\n",
        "                                # Import a graph_def into the current default Graph (In this case, the weights are (typically) embedded in the graph)\n",
        "\n",
        "                                tf.import_graph_def(\n",
        "                                graph_def,\n",
        "                                input_map=None,\n",
        "                                return_elements=None,\n",
        "                                name=\"xception_65\",\n",
        "                                op_dict=None,\n",
        "                                producer_op_list=None\n",
        "                                )\n",
        "\n",
        "                                # Print the name of operations in the session\n",
        "                                for op in graph.get_operations():\n",
        "                                        print (\"Operation Name :\",op.name )       # Operation name\n",
        "                                        print (\"Tensor Stats :\",str(op.values()))     # Tensor name\n",
        "\n",
        "                                # INFERENCE Here\n",
        "                                l_input = graph.get_tensor_by_name('ImageTensor:0') # Input Tensor\n",
        "                                l_output = graph.get_tensor_by_name('SemanticPredictions:0') # Output Tensor\n",
        "\n",
        "                                print (\"Shape of input : \", tf.shape(l_input))\n",
        "                                #initialize_all_variables\n",
        "                                tf.global_variables_initializer()\n",
        "\n",
        "                                # Run Kitty model on single image\n",
        "                                Session_out = sess.run( l_output, feed_dict = {l_input : image})\n",
        "                                print(Session_out[0][2])"
      ],
      "metadata": {
        "id": "tR6Z473A_hYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default() as g:\n",
        "    tf.train.import_meta_graph('/content/drive/MyDrive/models/ck_new/model.ckpt-30000.meta')\n",
        "\n",
        "with tf.Session(graph=g) as sess:\n",
        "    file_writer = tf.summary.FileWriter(logdir='/content/drive/MyDrive/models/out put folder check', graph=g)\n",
        "\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=\"/content/drive/MyDrive/models/out put folder check\"\n",
        "\n",
        "%tensorboard --logdir=visualization:\"/content/drive/MyDrive/models/out put folder check\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "BPKUwVxfYuah",
        "outputId": "1a61c164-16c1-412a-b348-0438642ecbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6007\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "gBkod9sA6ygh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a12245b-d31c-4c84-d61d-f18b335a4044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4dmmQFRa7mq",
        "outputId": "69f8e2f4-de06-468b-f287-7bb8ec0f611f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "import os\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import PIL.Image as Image\n",
        "\n",
        "\n",
        "INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "INPUT_SIZE = 513\n",
        "\n",
        "with tf.gfile.FastGFile('/content/drive/MyDrive/models/frozen_graph/prova.pb', \"rb\") as f:\n",
        "    graph_def = tf.GraphDef()\n",
        "    temp = f.read()\n",
        "    #print(temp,\"porco il clero\")\n",
        "    print(\"porco il clero nel dubbio\")\n",
        "    graph_def.ParseFromString(temp)\n",
        "    g_in = tf.import_graph_def(graph_def, name=\"prova.pb\")\n",
        "    sess = tf.Session(graph=g_in)\n",
        "\n",
        "\n",
        "def run(image):\n",
        "    width, height = image.size\n",
        "    resize_ratio = 1.0 * INPUT_SIZE / max(width, height)\n",
        "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "    resized_image = image.resize((513,513))\n",
        "    l_input = graph.get_tensor_by_name('ImageTensor:0') # Input Tensor\n",
        "    l_output = graph.get_tensor_by_name('SemanticPredictions:0') # Output Tensor\n",
        "    print([np.asarray(resized_image)].shape())\n",
        "    batch_seg_map = sess.run(\n",
        "        l_output,\n",
        "        feed_dict={l_input: [np.asarray(resized_image)]})\n",
        "    print(batch_seg_map.view)\n",
        "    seg_map = batch_seg_map[0]\n",
        "    return resized_image, seg_map\n",
        "\n",
        "input_image = Image.open('/content/drive/MyDrive/models/0000631.jpg')\n",
        "resized_im, seg_map = run(input_image)\n",
        "for cell in seg_map.flatten():\n",
        "  if cell != 0:\n",
        "    print(cell)\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(resized_im)\n",
        "fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(np.ma.masked_equal(seg_map, 0))"
      ],
      "metadata": {
        "id": "I0sdm8Lyfg1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagenet_classes\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.platform import gfile\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "dir_name = '/content/drive/MyDrive/models/frozen_graph'\n",
        "with tf.Graph().as_default() as graph:\n",
        "\twith tf.Session() as sess:\n",
        "\t\twith gfile.FastGFile(dir_name + \"/prova.pb\") as f:\n",
        "\t\t\tfile = '/content/drive/MyDrive/models/JPEGImages_all/0000001.jpg'\n",
        "\t\t\tinput = Image.open(file)\n",
        "\t\t\tinput = input.reshape(1, 513, 513, 3).astype(float)\n",
        "\t\t\tinput/=127.5\n",
        "\t\t\tinput-=1.\n",
        "\t\t\t\n",
        "\t\t\tgraph_def = tf.GraphDef()\n",
        "\t\t\tgraph_def.ParseFromString(f.read())\n",
        "\t\t\tsess.graph.as_default()\n",
        "\n",
        "\t\t\ttf.import_graph_def(graph_def, input_map=None, return_elements=None,\n",
        "\t\t\t\tname=\"\", op_dict=None, producer_op_list=None)\n",
        "\t\t\tfor op in graph.get_operations():\n",
        "\t\t\t\tprint(\"Operation Name :\" + op.name)\n",
        "\t\t\t\tprint(\"Tensor Stats :\" + str(op.values()))\n",
        "\t\t\tl_input = graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
        "\t\t\tl_output = graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)\n",
        "\t\t\ttf.global_variables_initializer()\n",
        "\t\t\top_prob = sess.run(l_output, feed_dict = {l_input : input})\n",
        "\t\t\tpreds = (np.argsort(op_prob[0])[::-1])[0:5]\n",
        "\t\t\tfor p in preds:\n",
        "\t\t\t    print(op_prob[0][p])"
      ],
      "metadata": {
        "id": "J2ARsCLeq8JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "GfARGNL9KLD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n"
      ],
      "metadata": {
        "id": "Y8ZRsMUgHxSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import tensorflow as tf\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000\"\n",
        "detection_graph = tf.Graph()\n",
        "INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "\n",
        "image = Image.open(\"/content/drive/MyDrive/models/0000631.jpg\")\n",
        "\n",
        "\n",
        "INPUT_SIZE = 513\n",
        "width, height = image.size\n",
        "resize_ratio = 1.0 * INPUT_SIZE / max(width, height)\n",
        "target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "print('Image resized')\n",
        "start_time = time.time()\n",
        "with tf.Session(graph=detection_graph) as sess:\n",
        "    # Load the graph with the trained states\n",
        "    loader = tf.train.import_meta_graph(model_path+'.meta')\n",
        "    loader.restore(sess, model_path)\n",
        "    # Get the tensors by their variable name\n",
        "    #output = detection_graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)\n",
        "    #input = detection_graph.get_tensor_by_name(INPUT_TENSOR_NAME)\n",
        "    #output = detection_graph.get_tensor_by_name(OUTPUT_TENSOR_NAME)\n",
        "    for x in [n.name for n in tf.get_default_graph().as_graph_def().node]:\n",
        "      print(x)\n",
        "    # Make predictions\n",
        "    batch_seg_map = sess.run(\n",
        "    'SemanticPredictions:0',\n",
        "    feed_dict={'ImageTensor:0': [np.asarray(resized_image)]})\n",
        "\n",
        "print('Image processing finished')\n",
        "print('Elapsed time : ' + str(time.time() - start_time))\n",
        "seg_map = batch_seg_map[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "86T52iiowd8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import tensorflow as tf\n",
        "import common\n",
        "import model\n",
        "INPUT_SIZE = 513\n",
        "\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  image = Image.open(\"/content/drive/MyDrive/models/0000631.jpg\")\n",
        "  \n",
        "  image_size = image.size\n",
        "  \n",
        "  width, height = image.size\n",
        "  resize_ratio = 1.0 * INPUT_SIZE / max(width, height)\n",
        "  target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "  resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "  resized_image_size = resized_image.size\n",
        "  model_options = common.ModelOptions(\n",
        "      outputs_to_num_classes={common.OUTPUT_TYPE: FLAGS.num_classes},\n",
        "      crop_size=FLAGS.crop_size,\n",
        "      atrous_rates=FLAGS.atrous_rates,\n",
        "      output_stride=FLAGS.output_stride)\n",
        "\n",
        "  if tuple(FLAGS.inference_scales) == (1.0,):\n",
        "    tf.logging.info('Exported model performs single-scale inference.')\n",
        "    predictions = model.predict_labels(\n",
        "        image,\n",
        "        model_options=model_options,\n",
        "        image_pyramid=FLAGS.image_pyramid)\n",
        "  else:\n",
        "    tf.logging.info('Exported model performs multi-scale inference.')\n",
        "    predictions = model.predict_labels_multi_scale(\n",
        "        image,\n",
        "        model_options=model_options,\n",
        "        eval_scales=FLAGS.inference_scales,\n",
        "        add_flipped_images=FLAGS.add_flipped_images)\n",
        "\n",
        "  predictions = tf.cast(predictions[common.OUTPUT_TYPE], tf.float32)\n",
        "  print(predictions)"
      ],
      "metadata": {
        "id": "-aRfAMF0B5tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import tensorflow as tf\n",
        "image = Image.open(\"/content/drive/MyDrive/models/0000631.jpg\")\n",
        "with tf.Session() as sess:\n",
        "  saver = tf.train.import_meta_graph(\"/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000.meta\")\n",
        "  saver.restore(sess,tf.train.latest_checkpoint('/content/drive/MyDrive/models/checkpoint_exc_all2/model.ckpt-30000'))\n",
        "  print(sess.run('w1:0'))\n",
        "\n",
        "  l = [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
        "  print(l)\n"
      ],
      "metadata": {
        "id": "Wg0Je8t_Kdeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hQoQ3Xz_fKtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/import_pb_to_tensorboard.py --model_dir \"/content/drive/MyDrive/models/frozen_graph/prova.pb\" --log_dir \"/content/drive/MyDrive/models/logdirpb\""
      ],
      "metadata": {
        "id": "vb4f7N0C7ue4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tf_slim\n",
        "!pip install pillow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "!python /content/drive/MyDrive/models/research/deeplab/eval.py --logtostderr \\\n",
        "  --eval_split=\"val\" \\\n",
        "  --model_variant=\"xception_65\" \\\n",
        "  --output_stride=16 \\\n",
        "  --decoder_output_stride=4 \\\n",
        "  --eval_crop_size=\"513,513\" \\\n",
        "  --dataset=\"pascal_voc_seg\" \\\n",
        "  --checkpoint_dir=\"/content/drive/MyDrive/models/ck_new\" \\\n",
        "  --eval_logdir=\"/content/drive/MyDrive/models/eval_logdir_exc_all2\"\\\n",
        "  --dataset_dir=\"/content/drive/MyDrive/models/tfrecord_all\" \\\n",
        "  --max_number_of_iterations=1 \\\n",
        "  --min_size =513 \\\n",
        "  --max_size =513 \\\n",
        "  --eval_interval_secs=0"
      ],
      "metadata": {
        "id": "ZP0kKQ7cpkGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class DeepLabModel(object):\n",
        "  \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "  INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "  OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "  INPUT_SIZE = 513\n",
        "  FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "  def __init__(self, tarball_path):\n",
        "    \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "    self.graph = tf.Graph()\n",
        "\n",
        "    graph_def = None\n",
        "    # Extract frozen graph from tar archive.\n",
        "    tar_file = tarfile.open(tarball_path)\n",
        "    for tar_info in tar_file.getmembers():\n",
        "      if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
        "        file_handle = tar_file.extractfile(tar_info)\n",
        "        graph_def = tf.GraphDef.FromString(file_handle.read())\n",
        "        break\n",
        "\n",
        "    tar_file.close()\n",
        "\n",
        "    if graph_def is None:\n",
        "      raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "    with self.graph.as_default():\n",
        "      tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "    self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "  def run(self, image):\n",
        "    \"\"\"Runs inference on a single image.\n",
        "\n",
        "    Args:\n",
        "      image: A PIL.Image object, raw input image.\n",
        "\n",
        "    Returns:\n",
        "      resized_image: RGB image resized from original input image.\n",
        "      seg_map: Segmentation map of `resized_image`.\n",
        "    \"\"\"\n",
        "    width, height = image.size\n",
        "    resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
        "    target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "    resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "    batch_seg_map = self.sess.run(\n",
        "        self.OUTPUT_TENSOR_NAME,\n",
        "        feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
        "    seg_map = batch_seg_map[0]\n",
        "    return resized_image, seg_map\n",
        "\n",
        "\n",
        "def create_pascal_label_colormap():\n",
        "  \"\"\"Creates a label colormap used in PASCAL VOC segmentation benchmark.\n",
        "\n",
        "  Returns:\n",
        "    A Colormap for visualizing segmentation results.\n",
        "  \"\"\"\n",
        "  colormap = np.zeros((256, 3), dtype=int)\n",
        "  ind = np.arange(256, dtype=int)\n",
        "\n",
        "  for shift in reversed(range(8)):\n",
        "    for channel in range(3):\n",
        "      colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
        "    ind >>= 3\n",
        "\n",
        "  return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "  \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "  Args:\n",
        "    label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "  Returns:\n",
        "    result: A 2D array with floating type. The element of the array\n",
        "      is the color indexed by the corresponding element in the input label\n",
        "      to the PASCAL color map.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If label is not of rank 2 or its value is larger than color\n",
        "      map maximum entry.\n",
        "  \"\"\"\n",
        "  if label.ndim != 2:\n",
        "    raise ValueError('Expect 2-D input label')\n",
        "\n",
        "  colormap = create_pascal_label_colormap()\n",
        "\n",
        "  if np.max(label) >= len(colormap):\n",
        "    raise ValueError('label value too large.')\n",
        "\n",
        "  return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map):\n",
        "  \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
        "  plt.figure(figsize=(15, 5))\n",
        "  grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
        "\n",
        "  plt.subplot(grid_spec[0])\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.title('input image')\n",
        "\n",
        "  plt.subplot(grid_spec[1])\n",
        "  seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "  plt.imshow(seg_image)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation map')\n",
        "\n",
        "  plt.subplot(grid_spec[2])\n",
        "  plt.imshow(image)\n",
        "  plt.imshow(seg_image, alpha=0.7)\n",
        "  plt.axis('off')\n",
        "  plt.title('segmentation overlay')\n",
        "\n",
        "  unique_labels = np.unique(seg_map)\n",
        "  ax = plt.subplot(grid_spec[3])\n",
        "  plt.imshow(\n",
        "      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "  ax.yaxis.tick_right()\n",
        "  plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "  plt.xticks([], [])\n",
        "  ax.tick_params(width=0.0)\n",
        "  plt.grid('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
        "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
        "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tv'\n",
        "])\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)\n",
        "\n",
        "\n",
        "MODEL_NAME = 'deeplabv3_pascal_train_aug' \n",
        "\n",
        "\n",
        "MODEL = DeepLabModel(\"/content/drive/MyDrive/models/frozen_graph/prova.pb\")\n",
        "print('model loaded successfully!')\n",
        "\n",
        "SAMPLE_IMAGE = \n",
        "IMAGE_URL = \n",
        "\n",
        "_SAMPLE_URL = ('https://github.com/tensorflow/models/blob/master/research/'\n",
        "               'deeplab/g3doc/img/%s.jpg?raw=true')\n",
        "\n",
        "\n",
        "def run_visualization(url):\n",
        "  \"\"\"Inferences DeepLab model and visualizes result.\"\"\"\n",
        "  try:\n",
        "    f = urllib.request.urlopen(url)\n",
        "    jpeg_str = f.read()\n",
        "    original_im = Image.open(BytesIO(jpeg_str))\n",
        "  except IOError:\n",
        "    print('Cannot retrieve image. Please check url: ' + url)\n",
        "    return\n",
        "\n",
        "  print('running deeplab on image %s...' % url)\n",
        "  resized_im, seg_map = MODEL.run(original_im)\n",
        "\n",
        "  vis_segmentation(resized_im, seg_map)\n",
        "\n",
        "\n",
        "image_url = IMAGE_URL or _SAMPLE_URL % SAMPLE_IMAGE\n",
        "run_visualization(image_url)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zvHzq_OTfkCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "print(tf.__version__)\n",
        "\n",
        "# Needed to show segmentation colormap labels\n",
        "\n",
        "flags = tf.compat.v1.app.flags\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "class DeepLabModel(object):\n",
        "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
        "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
        "    INPUT_SIZE = 513\n",
        "\n",
        "    def __init__(self, model_dir):\n",
        "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "        self.graph = tf.Graph()\n",
        "\n",
        "        graph_def = None\n",
        "        # Extract frozen graph from tar archive.\n",
        "        model_filename = model_dir\n",
        "        with tf.compat.v1.gfile.FastGFile(model_filename, 'rb') as f:\n",
        "            graph_def = tf.compat.v1.GraphDef()\n",
        "            graph_def.ParseFromString(open(\"/content/drive/MyDrive/models/frozen_graph/newmodeltrainval.pb\", \"rb\").read())\n",
        "\n",
        "        if graph_def is None:\n",
        "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            tf.import_graph_def(graph_def, name='')\n",
        "\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "    def run(self, image):\n",
        "        \"\"\"Runs inference on a single image.\n",
        "\n",
        "        Args:\n",
        "            image: A PIL.Image object, raw input image.\n",
        "\n",
        "        Returns:\n",
        "            resized_image: RGB image resized from original input image.\n",
        "            seg_map: Segmentation map of `resized_image`.\n",
        "        \"\"\"\n",
        "        width, height = image.size\n",
        "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
        "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
        "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "        #print('Image resized')\n",
        "        #print(np.asarray(resized_image))\n",
        "        \n",
        "        boh = np.asarray([np.asarray(resized_image)])\n",
        "        #print(boh.shape)\n",
        "        start_time = time.time()\n",
        "\n",
        "        batch_seg_map = self.sess.run(\n",
        "            self.OUTPUT_TENSOR_NAME,\n",
        "            feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
        "        print('Image processing finished')\n",
        "        print('Elapsed time : ' + str(time.time() - start_time))\n",
        "        seg_map = batch_seg_map[0]\n",
        "        return resized_image, seg_map\n",
        "\n",
        "\n",
        "model = DeepLabModel(\"\")\n",
        "print('Model created successfully')\n",
        "\n",
        "img = Image.open(\"/content/drive/MyDrive/models/0000631.jpg\")\n",
        "while True:\n",
        "  or_img, seg = model.run(img)\n",
        "\n",
        "\n",
        "  or_img.show()\n",
        "\n",
        "  from matplotlib import pyplot as plt\n",
        "  plt.imshow(seg, interpolation='nearest')\n",
        "  plt.show()\n",
        "\n",
        "  print(seg.shape)\n"
      ],
      "metadata": {
        "id": "sUS-fCP_29Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T935LeZ3CJc",
        "outputId": "637052ce-8b82-4762-c265-75141c60826a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD2GRSAqbNcw",
        "outputId": "475da570-59ca-434a-ede2-92b298530031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "#import source.skinSegmentation.skinSegmentation as SS\n",
        "import time\n",
        "from imutils.video import FPS\n",
        "from imutils.video import FPS\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "\n",
        "def show_webcam(mirror=False):\n",
        "    cv2.CAP_PROP_BUFFERSIZE = 0\n",
        "    cam = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        ret_val, img = cam.read()\n",
        "        start_time = time.time()\n",
        "        #maskSS = SS.skinSegmentation(img)\n",
        "        print('Elapsed time : ' + str(time.time() - start_time))\n",
        "        cv2.imshow('my webcam', img)\n",
        "        cv2.waitKey(1)\n",
        "        fps.update()\n",
        "        if cv2.waitKey(1) == 27:\n",
        "            break  # esc to quit\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def faster_stream():\n",
        "    # import the necessary packages\n",
        "\n",
        "    # construct the argument parse and parse the arguments\n",
        "    # open a pointer to the video stream and start the FPS timer\n",
        "    stream = cv2.VideoCapture(0)\n",
        "    fps = FPS().start()\n",
        "    # loop over frames from the video file stream\n",
        "    while True:\n",
        "        # grab the frame from the threaded video file stream\n",
        "        (grabbed, frame) = stream.read()\n",
        "        # if the frame was not grabbed, then we have reached the end\n",
        "        # of the stream\n",
        "        if not grabbed:\n",
        "            break\n",
        "        # resize the frame and convert it to grayscale (while still\n",
        "        # retaining 3 channels)\n",
        "        # display a piece of text to the frame (so we can benchmark\n",
        "        # fairly against the fast method)\n",
        "        # show the frame and update the FPS counter\n",
        "        #frame = SS.skinSegmentation(frame)\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        cv2.waitKey(1)\n",
        "        fps.update()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"avvio stream\")\n",
        "  print(cv2.VideoCapture(0).read())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lBQCX7vbJ0M",
        "outputId": "4b299fde-f2a0-4a35-e814-77f1789aa99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avvio stream\n",
            "(False, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "t2m2sDjNb8nV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "RTUregeqb8nW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copia_di_test_colab_deeplabv3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}